{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d892ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5137b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bloqade\n",
    "from bloqade.ir.location import Chain, start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a038e9ca-8a29-4b8d-993e-17fcb3470308",
   "metadata": {},
   "source": [
    "# Quantum Reservoir Computing Demo\n",
    "\n",
    "In this notebook we will show you how to train a model to classify MNIST images using quantum reservoir computing (QRC) with Bloqade. The general idea is that the chaotic, non-linear dynamics of quantum systems can be used to create a non-linear mapping from a low-dimensional space (which will be PCA embeddings extracted from the MNIST images) to a high dimensional space. In order to construct the mapping, we first ensure that information from the image will totally specify the dynamics of the quantum system. Then, we measure certain properties (in this case, spin expectations and correlations) over time. These measurements form the output of the mapping.   \n",
    "\n",
    "Through the embedding in this high dimensional space classification on using standard ML techniques is expected to perform better. \n",
    "\n",
    "This demo provides a toy model that does not require access to a quantum computer. It uses classical, numerical simulations of a quantum system with 8 qubits. The classical simulation makes use of the package Bloqade, which is designed for numerical simulations of neutral-atom architectures. With only a minimal of changes, we can use the same code to submit our jobs to Aquila hardware and analyse results.\n",
    "\n",
    "Neutral atom architectures provide access to several variational parameters. In this demo, we map pixelated descriptions of the images to the local detuning terms in the Rydberg Hamiltonian. We then measure the quantum system and train the classical model which maps the quantum readout from the measurement to the desired prediction. As all training process is in the classical part (excuted on a classical computer), we expect the training is substantially shorter than other traditional quantum machine learning models. More details on numerical simulation of neutral-atom architectures, and the range of the parameters can be found from [Bloqade](https://github.com/QuEraComputing/bloqade-python) documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea12b36-2f1c-4538-8cec-c365091a7d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Download the MNIST dataset and rescaling data\n",
    "                     \n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "train_X, test_X = train_X / 255.0, test_X / 255.0\n",
    "\n",
    "## training data set (each image has 28x28 pixels and there are 60000 training samples)\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "\n",
    "## test data set (10000 test samples)\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122d68ab-68f0-4d82-a0a1-3217d480bbba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of an training dataset image for '5'\n",
    "plt.imshow(train_X[0], cmap=plt.get_cmap('gray'), interpolation='None')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "958cbc65-6686-42c5-9883-389e4498d14d",
   "metadata": {},
   "source": [
    "## PCA Reduction\n",
    "\n",
    "In this notebook, we first train a toy model using 1000 samples from the MNIST dataset.\n",
    "\n",
    "The images form the input into the quantum system. As we focus on numerical simulation where the number of atoms in the quantum system is limited, we first perform dimensionality reduction using the [principal component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc2f07f-b04f-4e06-946f-1c7baef0a677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set PCA: \n",
      "  [[ 0.48601015  1.22617358  0.09613354  2.17944297 -0.10704576  0.9116717\n",
      "   0.91763033  0.62666468]\n",
      " [ 3.96752304  1.15630211 -2.33858651  1.80692626 -3.24421656  0.71353148\n",
      "  -0.17655089 -0.41164546]\n",
      " [-0.2033318  -1.53793393  0.73925392 -2.04318175 -1.20266952  0.00719743\n",
      "  -3.36881255  1.44545833]\n",
      " [-3.13383152  2.38116556 -1.07314212 -0.41520877 -0.00726755 -2.74374391\n",
      "  -1.85769884 -0.2640067 ]\n",
      " [-1.50099977 -2.86487399 -0.06413234  0.94783341  0.38494646 -0.16952834\n",
      "  -0.35947686 -1.59041131]] \n",
      "\n",
      "Test set PCA: \n",
      "  [[ 0.48601015  1.22617358  0.09613354  2.17944297 -0.10704576  0.9116717\n",
      "   0.91763033  0.62666468]\n",
      " [ 3.96752304  1.15630211 -2.33858651  1.80692626 -3.24421656  0.71353148\n",
      "  -0.17655089 -0.41164546]\n",
      " [-0.2033318  -1.53793393  0.73925392 -2.04318175 -1.20266952  0.00719743\n",
      "  -3.36881255  1.44545833]\n",
      " [-3.13383152  2.38116556 -1.07314212 -0.41520877 -0.00726755 -2.74374391\n",
      "  -1.85769884 -0.2640067 ]\n",
      " [-1.50099977 -2.86487399 -0.06413234  0.94783341  0.38494646 -0.16952834\n",
      "  -0.35947686 -1.59041131]] \n"
     ]
    }
   ],
   "source": [
    "# We first use PCA to downsample the data into 10-dimensional vectors\n",
    "dim_pca = 8\n",
    "\n",
    "# Use the `fit` function from the `sklearn` package to define the PCA model and apply to training set\n",
    "pca=PCA(n_components=dim_pca).fit(np.reshape(train_X, (60000,28*28)))\n",
    "x=pca.transform(np.reshape(train_X, (60000,28*28)))\n",
    "\n",
    "# Let us see how it looks\n",
    "num_examples = 1000\n",
    "xs = x[:num_examples,:]\n",
    "print(\"Training set PCA: \\n \", xs[0:5,:], \"\\n\")\n",
    "\n",
    "#processing the test set\n",
    "xt=pca.transform(np.reshape(test_X, (10000,28*28)))\n",
    "\n",
    "# Let us see how it looks\n",
    "num_test_examples = 200\n",
    "xs_test = xt[:num_test_examples,:]\n",
    "print(\"Test set PCA: \\n \", xs[0:5,:], \"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b8dd2d9",
   "metadata": {},
   "source": [
    "Here, we scale the range of principal components to a feasible range for local detuning implementation, [0, 1]. And later, for each image, we will encode each of the 8 scaled principal components into each single local detuning for 8 atoms. For more details of the neutral atom quantum system, please refer to the documentation of [Bloqade](https://queracomputing.github.io/Bloqade.jl/dev/#What-does-Bloqade-Do?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5a7bc3-9d38-4a86-bb7e-ad8be8eb481e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectral =(np.amax(xs) - np.amin(xs))\n",
    "m1=np.amin(xs)\n",
    "xs = (xs - m1)/spectral # to make sure values to be between [0, 1]\n",
    "xs_test = (xs_test - m1)/spectral # the same transformation on the test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb7e3094-94c8-4dce-b631-660a094c7475",
   "metadata": {},
   "source": [
    "## Build quantum tasks and simulate dynamics\n",
    "\n",
    "We can now set up the quantum simulation. \n",
    "\n",
    "- Define a `dictionary`, which captures all physical parameters and readouts of the quantum system.\n",
    "- Define functions that simulate quantum dynamics or build tasks that can me submitted to hardware with the input `x` from scaled detunings \n",
    "- The simulation of the quantum dynamics has been implemented in [Bloqade](https://github.com/QuEraComputing/bloqade-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67796a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "QRC_parameters={\n",
    "    \"atom_number\":dim_pca, #number of atoms, equal to the dimension of PCA feature vector\n",
    "    \"geometry_spec\":Chain(dim_pca, lattice_spacing=10), #atom geometry - we will use a linear chain with 10 micron distance between atoms\n",
    "    \"encoding_scale\":9.0, #scaling factor for local detuning encoding\n",
    "    \"rabi_frequency\":6.283,#value of Rabi frequency used\n",
    "    \"total_time\":4, #total maximum evolution time - 4 microseconds\n",
    "    \"time_steps\":8, #number of probe times for quantum embedding collection - 8 in the 4 microsecond window\n",
    "    \"readouts\":\"ZZ\", #includes both ZZ correlators together with default Rydberg density as generated embeddings\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1e17c",
   "metadata": {},
   "source": [
    "Here, we define the function that will proccess the QRC parameters define above and return a task that can be either simulated or ran on hardware. In addition, we define the processing pipeline that will turn the samples collected on hardware or in simulation into QRC embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffae4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function for building quantum tasks.\n",
    "def build_task(QRC_parameters, xs1):\n",
    "    natoms=QRC_parameters[\"atom_number\"]\n",
    "    encoding_scale=QRC_parameters[\"encoding_scale\"]\n",
    "    dt=QRC_parameters[\"total_time\"]/QRC_parameters[\"time_steps\"]\n",
    "    #builds global Rabi and detuning pulses\n",
    "    rabi_oscillations_program = (QRC_parameters[\"geometry_spec\"]\n",
    "            .rydberg.rabi.amplitude.uniform.constant(\n",
    "                duration=\"run_time\", value=QRC_parameters[\"rabi_frequency\"]\n",
    "            )\n",
    "            .detuning.uniform.constant(duration=\"run_time\", value=encoding_scale/2)\n",
    "            #adds local detuning according to the feature vector\n",
    "            .scale(list(xs1)).constant(duration=\"run_time\", value=-encoding_scale)\n",
    "            ) \n",
    "    rabi_oscillation_job = rabi_oscillations_program.batch_assign(run_time=np.arange(1, QRC_parameters[\"time_steps\"]+1, 1)*dt)\n",
    "    #`batch_assign` used to probe the quantum reservoir at set number of timesteps\n",
    "    return rabi_oscillation_job\n",
    "\n",
    "#To obtain the embeddings, we process the report containing the collected samples into embeddins made of Z and ZZ observables.\n",
    "def process_results(QRC_parameters, report):  \n",
    "    embedding=[]\n",
    "    natoms=QRC_parameters[\"atom_number\"]\n",
    "    try:\n",
    "        for t in range(QRC_parameters[\"time_steps\"]):\n",
    "            ar1=-1.0+2*((report.bitstrings())[t])\n",
    "            nsh1=ar1.shape[0]\n",
    "            for i in range(natoms):\n",
    "                embedding.append(np.sum(ar1[:,i])/nsh1) #Z expectation values\n",
    "            if QRC_parameters[\"readouts\"]==\"ZZ\":\n",
    "                for i in range(natoms):\n",
    "                    for j in range(i+1,natoms):\n",
    "                        embedding.append(np.sum(ar1[:,i]*ar1[:,j])/nsh1) #ZZ expectation values\n",
    "    except: #In case no experimental results were obtained.\n",
    "        print(\"No results exist.\")\n",
    "        for t in range(QRC_parameters[\"time_steps\"]):\n",
    "            for i in range(natoms):\n",
    "                embedding.append(0.0)\n",
    "            if QRC_parameters[\"readouts\"]==\"ZZ\":\n",
    "                for i in range(natoms):\n",
    "                    for j in range(i+1,natoms):\n",
    "                        embedding.append(0.0)\n",
    "    return embedding\n",
    "\n",
    "#Processing if only samples are needed.\n",
    "def process_results_samples(QRC_parameters, report):  \n",
    "    embedding=[]\n",
    "    natoms=QRC_parameters[\"atom_number\"]\n",
    "    try:\n",
    "        embedding=report.bitstrings()\n",
    "        # for t in range(QRC_parameters[\"time_steps\"]):\n",
    "        #     ar1=-1.0+2*((report.bitstrings())[t])\n",
    "        #     nsh1=ar1.shape[0]\n",
    "        #     for i in range(natoms):\n",
    "        #         embedding.append(np.sum(ar1[:,i])/nsh1) #Z expectation values\n",
    "        #     if QRC_parameters[\"readouts\"]==\"ZZ\":\n",
    "        #         for i in range(natoms):\n",
    "        #             for j in range(i+1,natoms):\n",
    "        #                 embedding.append(np.sum(ar1[:,i]*ar1[:,j])/nsh1) #ZZ expectation values\n",
    "    except: #In case no experimental results were obtained.\n",
    "        print(\"No results exist.\")\n",
    "        for t in range(QRC_parameters[\"time_steps\"]):\n",
    "            for i in range(natoms):\n",
    "                embedding.append(0.0)\n",
    "            if QRC_parameters[\"readouts\"]==\"ZZ\":\n",
    "                for i in range(natoms):\n",
    "                    for j in range(i+1,natoms):\n",
    "                        embedding.append(0.0)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51321f29",
   "metadata": {},
   "source": [
    "In order to generate QRC embeddings, we will call emulation routines for the tasks we build and process the resulting data. We will collect 1000 samples per datapoint in emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea54345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Simulating and gathering samples only\n",
    "# samples_train=np.array([process_results_samples(QRC_parameters, \n",
    "#         build_task(QRC_parameters, xs[data,:]).bloqade.python().run(shots=100, rtol=1e-8, atol=1e-8).report())\n",
    "#         for data in range(num_examples)])\n",
    "# np.save(\"samples_train.npy\", samples_train)\n",
    "# samples_test=np.array([process_results_samples(QRC_parameters, \n",
    "#         build_task(QRC_parameters, xs_test[data,:]).bloqade.python().run(shots=100, rtol=1e-8, atol=1e-8).report())\n",
    "#         for data in range(num_test_examples)])\n",
    "# np.save(\"samples_test.npy\", samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43caeabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_emulation(xs, num_examples, nshots=1000):\n",
    "    return np.array([process_results(QRC_parameters, \n",
    "        build_task(QRC_parameters, xs[data,:]).bloqade.python().run(shots=nshots, rtol=1e-8, atol=1e-8).report())\n",
    "        for data in range(num_examples)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a553c9b",
   "metadata": {},
   "source": [
    "Now, we are ready to run the simulation by apply the defined emulation pipeline to the scaled feature vectors! For each image, the readouts from the quantum dynamics is a 288-dimensional vector which has much higher dimension than the PCA dimension. The full results will be stored in a $1000\\times 288$ matrix `embeddings`.\n",
    "\n",
    "(It might take a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac5935be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=get_embeddings_emulation(xs, num_examples, nshots=1000)\n",
    "test_embeddings=get_embeddings_emulation(xs_test, num_test_examples, nshots=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "067eac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 288)\n",
      "(200, 288)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)\n",
    "print(test_embeddings.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4fc61b5-2e5e-4954-8cc9-eccacc34c1f1",
   "metadata": {},
   "source": [
    "## Training Neural Network and Evaluating Performance\n",
    "\n",
    "Now we are going to train a classical neural network without hidden layers (a linear classifier with `softmax` output function), using quantum measurements stored in `embeddings` as the input. In comparision, we also trained a neural network without hidden layers directly using PCA feature vectors without the quantum reservoir processing, as well as a simple neural network with two hidden layers for comparison.\n",
    "\n",
    "Here, we used the machine learning framework of [tensorflow](https://www.tensorflow.org/) for the neural network training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a971b",
   "metadata": {},
   "source": [
    "First, let's see the results of a linear classifier applied on PCA features directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe750ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA test accuracy: 69.0 %\n"
     ]
    }
   ],
   "source": [
    "#building a linear model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#fitting to train data\n",
    "model.fit(xs, train_y[:num_examples], epochs=1000, batch_size=100, verbose=0)\n",
    "\n",
    "#evaluating on test data\n",
    "test_loss, test_acc = model.evaluate(xs_test,  test_y[:num_test_examples], verbose=0)\n",
    "print('PCA test accuracy:', 100*round(test_acc, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d3e316",
   "metadata": {},
   "source": [
    "And now, let's apply the same linear classifier on our QRC embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ffd5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QRC test accuracy: 83.0 %\n"
     ]
    }
   ],
   "source": [
    "#building a linear model\n",
    "#we include regularization and tune epsilon parameter of the optimizer to better control training from QRC embeddings generated on finite number of samples\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.L1(l1=0.0001))\n",
    "    ])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(epsilon=0.0002),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#fitting to train data\n",
    "model.fit(embeddings, train_y[:num_examples], epochs=2000, batch_size=100, verbose=0)\n",
    "\n",
    "#evaluating on test data\n",
    "test_loss, test_acc = model.evaluate(test_embeddings,  test_y[:num_test_examples], verbose=0)\n",
    "print('QRC test accuracy:', 100*round(test_acc, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc8b956",
   "metadata": {},
   "source": [
    "QRC embeddings significantly outperform linear classifier on PCA embeddings only!\n",
    "\n",
    "Finally, let's compare with a sizable classical neural network with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "266a1d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-layer NN test accuracy: 81.0 %\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(10),\n",
    "\n",
    "    ])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(xs, train_y[:num_examples], epochs=1000, batch_size=100, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(xs_test,  test_y[:num_test_examples], verbose=0)\n",
    "print('4-layer NN test accuracy:', 100*round(test_acc, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe25659",
   "metadata": {},
   "source": [
    "While in this case classical neural network outperforms QRC, this is a consequence of limited dataset size. With more data, QRC will match the 4-layer neural network performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5333d324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mkornjaca\\anaconda3\\envs\\blpy_June\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM test accuracy: 70.0 %\n",
      "SVC test accuracy (rbf kernel): 89.0 %\n",
      "QRC test accuracy: 84.0 %\n"
     ]
    }
   ],
   "source": [
    "#The same implemented with LinearSVC and SVC from sklearn.\n",
    "\n",
    "svm = LinearSVC(C=1.0, multi_class='crammer_singer', dual=False)\n",
    "svm.fit(xs, train_y[:num_examples])\n",
    "y_pred = svm.predict(xs_test)\n",
    "accuracy=svm.score(xs_test, test_y[:num_test_examples])\n",
    "print('Linear SVM test accuracy:', 100*round(accuracy, 2), \"%\")\n",
    "\n",
    "svm = SVC(C=8.)\n",
    "svm.fit(xs, train_y[:num_examples])\n",
    "y_pred = svm.predict(xs_test)\n",
    "accuracy=svm.score(xs_test, test_y[:num_test_examples])\n",
    "print('SVC test accuracy (rbf kernel):', 100*round(accuracy, 2), \"%\")\n",
    "\n",
    "\n",
    "svm = LinearSVC(C=1.0, multi_class='crammer_singer', dual=False)\n",
    "svm.fit(embeddings, train_y[:num_examples])\n",
    "y_pred = svm.predict(embeddings)\n",
    "accuracy=svm.score(test_embeddings, test_y[:num_test_examples])\n",
    "print('QRC test accuracy:', 100*round(accuracy, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5456543f",
   "metadata": {},
   "source": [
    "## Implementation on Aquila"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98194b5",
   "metadata": {},
   "source": [
    "The convenience of [Bloqade](https://github.com/QuEraComputing/bloqade-python) allows us to submit the same tasks to Aquila with only minimal changes and test our algorithm! Let's start by gathering AWS braket credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad2cec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS braket credentials\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"key1\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"key2\"\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = \"key3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b1d222",
   "metadata": {},
   "source": [
    "We are now ready to submit the tasks that we emulated. The only difference from emulation is that we're going to save are tasks as we'll have to wait for their turn in the Aquila queue. \n",
    "\n",
    "In addition, for basic tests, we will lower the number of shots that we gather for each image. While the performance will neccesarily be lower than in emulation,  this will allow us to obtain results faster for the proof of principle showcase. Furthermore, we will use the built-in `parallelize` Bloqade capability, that we'll allow us to paralelize our sampling by running several instances of our atom chain in parallel on Aquila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "583b9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tasks=\"./qrc_tasks\"\n",
    "if not os.path.exists(path_to_tasks):\n",
    "  os.mkdir(path_to_tasks)\n",
    "  \n",
    "\n",
    "#Train task submissions\n",
    "nshots=10 #The actual number of shots collected per image will be 60, as we parallelize our sampling with 6 chains that are 15 micrometers appart.\n",
    "for data in range(num_examples):\n",
    "    try:\n",
    "        #task=build_task(QRC_parameters, xs[data,:]).parallelize(15).braket.aquila().run_async(shots=nshots, name = \"QRC_train_\"+str(data))\n",
    "        task=build_task(QRC_parameters, xs[data,:]).parallelize(15).quera.mock().run_async(shots=nshots, name = \"QRC_train_\"+str(data))\n",
    "        bloqade.save(\n",
    "            task,\n",
    "            path_to_tasks + \"/\" + \"qrc_train_\" + str(data) + \".json\",       \n",
    "        )\n",
    "    except:\n",
    "       print(\"Training task \" + str(data) + \" was not submitted.\")\n",
    "\n",
    "\n",
    "\n",
    "#Test task submissions\n",
    "for data in range(num_test_examples):\n",
    "    try:\n",
    "        #task=build_task(QRC_parameters, xs[data,:]).parallelize(15).braket.aquila().run_async(shots=nshots, name = \"QRC_test_\"+str(data))\n",
    "        task=build_task(QRC_parameters, xs_test[data,:]).parallelize(15).quera.mock().run_async(shots=nshots, name = \"QRC_test_\"+str(data))\n",
    "        bloqade.save(\n",
    "            task,\n",
    "            path_to_tasks + \"/\" + \"qrc_test_\" + str(data) + \".json\",       \n",
    "        )\n",
    "    except:\n",
    "       print(\"Test task \" + str(data) + \" was not submitted.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282e822",
   "metadata": {},
   "source": [
    "Once the tasks have been completed, we gather Aquila results and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_results=\"./qrc_results\"\n",
    "if not os.path.exists(path_to_results):\n",
    "  os.mkdir(path_to_results)\n",
    "\n",
    "\n",
    "#Train task fetching\n",
    "for data in range(num_examples):\n",
    "    try:\n",
    "        task = bloqade.load(path_to_tasks + \"/\" + \"qrc_train_\" + str(data) + \".json\")\n",
    "        bloqade.save(\n",
    "            task.fetch(),\n",
    "            path_to_results + \"/\" + \"qrc_train_\" + str(data) + \".json\",       \n",
    "        )\n",
    "    except:\n",
    "        print(\"Training task \" + str(data) + \" was not saved.\")\n",
    "\n",
    "#Test task fetching\n",
    "for data in range(num_test_examples):\n",
    "    try:\n",
    "        task = bloqade.load(path_to_tasks + \"/\" + \"qrc_test_\" + str(data) + \".json\")\n",
    "        bloqade.save(\n",
    "            task.fetch(),\n",
    "            path_to_results + \"/\" + \"qrc_test_\" + str(data) + \".json\",       \n",
    "        )\n",
    "    except:\n",
    "        print(\"Test task \" + str(data) + \" was not saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916cf7a",
   "metadata": {},
   "source": [
    "Just like that, everything is in place for generating QRC embeddings from hardware. We can even use the same processing pipeline as for emulator results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_Aquila=[]\n",
    "for data in range(num_examples):\n",
    "    task_report = bloqade.load(path_to_results + \"/\" + \"qrc_train_\" + str(data) + \".json\").report()\n",
    "    embeddings.append(process_results(QRC_parameters,task_report))\n",
    "embeddings_Aquila=np.array(embeddings_Aquila)\n",
    "\n",
    "test_embeddings_Aquila=[]\n",
    "for data in range(num_test_examples):\n",
    "    task_report = bloqade.load(path_to_results + \"/\" + \"qrc_train_\" + str(data) + \".json\").report()\n",
    "    test_embeddings_Aquila.append(process_results(QRC_parameters,task_report))\n",
    "test_embeddings_Aquila=np.array(test_embeddings_Aquila)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0936b3f",
   "metadata": {},
   "source": [
    "Finally, let's train our linear classification layer on Aquila embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ee78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a linear model\n",
    "#we include regularization and tune epsilon parameter of the optimizer to better control training from QRC embeddings generated on finite number of samples\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.L1(l1=0.02))\n",
    "    ])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(epsilon=0.0002),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#fitting to train data\n",
    "model.fit(embeddings_Aquila, train_y[:num_examples], epochs=1500, batch_size=100, verbose=0)\n",
    "\n",
    "#evaluating on test data\n",
    "test_loss, test_acc = model.evaluate(test_embeddings_Aquila,  test_y[:num_test_examples], verbose=0)\n",
    "print('QRC test accuracy on Aquila:', 100*round(test_acc, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04939493",
   "metadata": {},
   "source": [
    "Aquila has succesfully performed MNIST classification! Note, due to the limited sampling for this proof of principle experiment, the performance is significantly below the emulated performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54507233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
